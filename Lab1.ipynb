{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Python\n",
    "\n",
    "## Background\n",
    "\n",
    "Sentiment Analysis is a NLP technique for determining the\n",
    "opinion polarity for a given text. Let's apply this technique\n",
    "move reviews.\n",
    "\n",
    "\"I love this movie!\" <- (positive)\n",
    "\n",
    "\"This movie really stinks :-(\" <- (negative)\n",
    "\n",
    "### First, import the required libraries\n",
    "\n",
    "We're using the Python Natural Language Toolkit Library (NLTK),\n",
    "it includes many datasets, NLP and ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's preprocess our data\n",
    "\n",
    "A common dataset for training sentiment analysis algorithms\n",
    "is the IMDB movie review dataset. It contains thousands of\n",
    "movie reviews with their sentiment polarity labeled (pos/neg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "negative_ids = movie_reviews.fileids('neg')\n",
    "positive_ids = movie_reviews.fileids('pos')\n",
    "\n",
    "print(movie_reviews.sents(negative_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a function to create our `features`. Features\n",
    "are names given to data that can be used in a learning algorithm.\n",
    "Features can be different types dependent on the algorithm being\n",
    "used, but typically are binary or float values. Therefore, a\n",
    "transform is necessary to convert our textual data into numerical\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    return dict([(word, True) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the positive and negative `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "negative_features = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negative_ids]\n",
    "positive_features = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in positive_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates two lists of dictionaries, where every dict\n",
    "corresponds to the set of words found in a particular positive or negative\n",
    "document.\n",
    "\n",
    "Next, we need to split our labeled data into training and\n",
    "testing data sets. Why? We want to be able to test how accurate\n",
    "the model we are going to develop is, in order to do that we\n",
    "need labeled data to test on. An 80/20 split is typical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "neg_cutoff = round(len(negative_features) * 0.80)\n",
    "pos_cutoff = round(len(positive_features) * 0.80)\n",
    "training_features = negative_features[:neg_cutoff] + positive_features[:pos_cutoff]\n",
    "testing_features = negative_features[neg_cutoff:] + positive_features[pos_cutoff:]\n",
    "print('train on %d instances, test on %d instances' % (len(training_features), len(testing_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification\n",
    "We're ready to train our model. One of the simplest Machine Learning algorithms is the Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(training_features)\n",
    "print('accuracy:', nltk.classify.util.accuracy(classifier, testing_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we get any sense of how these decisions are being made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, cool. What about on some new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_reviews = [\n",
    "\"\"\"Wow! That's about all one can say about this movie. The first time that I saw\n",
    "it I was mesmerized. The movie looked so cool and hey, it actually had a good\n",
    "plot. If you haven't seen this movie yet, get out from your cave and see it\n",
    "right away. I have seen this movie umpteen times and it still shocks and\n",
    "surprises me. \"\"\",\n",
    "\"\"\"Anyway, back to the movie. It is as bad as you've no doubt heard. The scene\n",
    "changes from night to day to night, the spaceship is a hubcap (you can see the\n",
    "string it hangs from catch on fire at one point), I could do a better job\n",
    "acting, etc.\"\"\"]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for review in test_reviews:\n",
    "    review_features = word_feats(word_tokenize(review.lower()))\n",
    "    label = classifier.classify(review_features)\n",
    "    prob_results = classifier.prob_classify(review_features)\n",
    "    prob_str = \" ({0:.2}/{1:.2})\".format(prob_results.prob(\"pos\"), prob_results.prob(\"neg\"))\n",
    "    print(review[:25], \": \", label, prob_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Decision Tree, Support Vector Machines. Ways of improving the features, tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
