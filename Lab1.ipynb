{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Python\n",
    "\n",
    "## Background\n",
    "\n",
    "Sentiment Analysis is a NLP technique for determining the\n",
    "opinion polarity for a given text. Let's apply this technique\n",
    "move reviews.\n",
    "\n",
    "\"I love this movie!\" <- (positive)\n",
    "\n",
    "\"This movie really stinks :-(\" <- (negative)\n",
    "\n",
    "### First, import the required libraries\n",
    "\n",
    "We're using the Python Natural Language Toolkit Library (NLTK),\n",
    "it includes many datasets, NLP and ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let's preprocess our data\n",
    "\n",
    "A common dataset for training sentiment analysis algorithms\n",
    "is the IMDB movie review dataset. It contains thousands of\n",
    "movie reviews with their sentiment polarity labeled (pos/neg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "negative_ids = movie_reviews.fileids('neg')\n",
    "positive_ids = movie_reviews.fileids('pos')\n",
    "\n",
    "print(movie_reviews.sents(negative_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a function to create our `features`. Features\n",
    "are names given to data that can be used in a learning algorithm.\n",
    "Features can be different types dependent on the algorithm being\n",
    "used, but typically are binary or float values. Therefore, a\n",
    "transform is necessary to convert our textual data into numerical\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def word_feats(words):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return dict([(ps.stem(word), True) for word in words if not word in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the positive and negative `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_features = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negative_ids]\n",
    "positive_features = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in positive_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates two lists of dictionaries, where every dict\n",
    "corresponds to the set of words found in a particular positive or negative\n",
    "document.\n",
    "\n",
    "Next, we need to split our labeled data into training and\n",
    "testing data sets. Why? We want to be able to test how accurate\n",
    "the model we are going to develop is, in order to do that we\n",
    "need labeled data to test on. An 80/20 split is typical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "800\n800\ntrain on 1600 instances, test on 400 instances\n"
     ]
    }
   ],
   "source": [
    "neg_cutoff = round(len(negative_features) * 0.80)\n",
    "print(neg_cutoff)\n",
    "pos_cutoff = round(len(positive_features) * 0.80)\n",
    "print(pos_cutoff)\n",
    "training_features = negative_features[:neg_cutoff] + positive_features[:pos_cutoff]\n",
    "testing_features = negative_features[neg_cutoff:] + positive_features[pos_cutoff:]\n",
    "print('train on %d instances, test on %d instances' % (len(training_features), len(testing_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification\n",
    "We're ready to train our model. One of the simplest Machine Learning algorithms is the Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(training_features)\n",
    "print('accuracy:', nltk.classify.util.accuracy(classifier, testing_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we get any sense of how these decisions are being made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     13.9 : 1.0\n",
      "               insulting = True              neg : pos    =     13.7 : 1.0\n",
      "              vulnerable = True              pos : neg    =     13.0 : 1.0\n",
      "               ludicrous = True              neg : pos    =     12.6 : 1.0\n",
      "             uninvolving = True              neg : pos    =     12.3 : 1.0\n",
      "              astounding = True              pos : neg    =     11.7 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             fascination = True              pos : neg    =     11.0 : 1.0\n",
      "               affecting = True              pos : neg    =     10.3 : 1.0\n",
      "               animators = True              pos : neg    =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, cool. What about on some new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wow! That's about all one :  neg  (0.31/0.69)\nAnyway, back to the movie :  neg  (0.38/0.62)\n"
     ]
    }
   ],
   "source": [
    "test_reviews = [\n",
    "\"\"\"Wow! That's about all one can say about this movie. The first time that I saw\n",
    "it I was mesmerized. The movie looked so cool and hey, it actually had a good\n",
    "plot. If you haven't seen this movie yet, get out from your cave and see it\n",
    "right away. I have seen this movie umpteen times and it still shocks and\n",
    "surprises me.\"\"\",\n",
    "\"\"\"Anyway, back to the movie. It is as bad as you've no doubt heard. The scene\n",
    "changes from night to day to night, the spaceship is a hubcap (you can see the\n",
    "string it hangs from catch on fire at one point), I could do a better job\n",
    "acting, etc. \"\"\"]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for review in test_reviews:\n",
    "    review_features = word_feats(word_tokenize(review.lower()))\n",
    "    label = classifier.classify(review_features)\n",
    "    prob_results = classifier.prob_classify(review_features)\n",
    "    prob_str = \" ({0:.2}/{1:.2})\".format(prob_results.prob(\"pos\"), prob_results.prob(\"neg\"))\n",
    "    print(review[:25], \": \", label, prob_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Decision Tree, Support Vector Machines. Ways of improving the features, tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}