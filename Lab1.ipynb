{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with Naive-Bayes & Python\n",
    "\n",
    "## Typical Supervised ML Workflow\n",
    "\n",
    "1. Acquire Data\n",
    "2. Preprocess / Clean Data\n",
    "3. Build a feature set\n",
    "4. Build a training model\n",
    "5. Apply the model to tuning or test data\n",
    "6. Score the results of the trained model\n",
    "7. Revise hypothesis, train & test again until reach acceptable performance\n",
    "\n",
    "## Background\n",
    "\n",
    "Sentiment Analysis is a NLP technique for determining the\n",
    "opinion polarity for a given text.\n",
    "\n",
    "Let's apply this technique move reviews!\n",
    "\n",
    "### What is the task?\n",
    "\n",
    "For the following two reviews we'd expect to receive the two subsequent \"labels\"\n",
    " of their sentiment.\n",
    "\n",
    "| Review  \t                        | Label |\n",
    "|---\t                            |---\t|\n",
    "| \"I love this movie!\"   \t        | `pos`\t|\n",
    "| \"This movie really stinks :-(\"  \t| `neg`\t|\n",
    "\n",
    "### First we need to ACQUIRE & PREPROCESS our data\n",
    "\n",
    "A common dataset for training sentiment analysis algorithms\n",
    "is the IMDB movie review dataset. It contains thousands of\n",
    "movie reviews along with their sentiment polarity labeling (i.e., pos/neg.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "negative_ids = movie_reviews.fileids('neg')\n",
    "positive_ids = movie_reviews.fileids('pos')\n",
    "\n",
    "print(movie_reviews.sents(negative_ids[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets define a function to create our `features`. Features\n",
    "are names given to data that can be used in a learning algorithm.\n",
    "Features can be different types dependent on the algorithm being\n",
    "used, but typically are binary or float values. Therefore, a\n",
    "transform is necessary to convert our textual data into numerical\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "\n",
    "def word_feats(words):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return dict([(ps.stem(word), True) for word in words if not word in stop_words])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the positive and negative `features`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_features = [(word_feats(movie_reviews.words(fileids=[f])), 'neg') for f in negative_ids]\n",
    "positive_features = [(word_feats(movie_reviews.words(fileids=[f])), 'pos') for f in positive_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates two lists of dictionaries, where every dict\n",
    "corresponds to the set of words found in a particular positive or negative\n",
    "document.\n",
    "\n",
    "Next, we need to split our labeled data into training and\n",
    "testing data sets. Why? We want to be able to test how accurate\n",
    "the model we are going to develop is, in order to do that we\n",
    "need labeled data to test on. An 80/20 split is typical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "800\n800\ntrain on 1600 instances, test on 400 instances\n"
     ]
    }
   ],
   "source": [
    "neg_cutoff = round(len(negative_features) * 0.80)\n",
    "print(neg_cutoff)\n",
    "pos_cutoff = round(len(positive_features) * 0.80)\n",
    "print(pos_cutoff)\n",
    "training_features = negative_features[:neg_cutoff] + positive_features[:pos_cutoff]\n",
    "testing_features = negative_features[neg_cutoff:] + positive_features[pos_cutoff:]\n",
    "print('train on %d instances, test on %d instances' % (len(training_features), len(testing_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification\n",
    "We're ready to train our model. One of the simplest Machine Learning algorithms is the Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(training_features)\n",
    "print('accuracy:', nltk.classify.util.accuracy(classifier, testing_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we get any sense of how these decisions are being made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Most Informative Features\n",
      "             outstanding = True              pos : neg    =     13.9 : 1.0\n",
      "               insulting = True              neg : pos    =     13.7 : 1.0\n",
      "              vulnerable = True              pos : neg    =     13.0 : 1.0\n",
      "               ludicrous = True              neg : pos    =     12.6 : 1.0\n",
      "             uninvolving = True              neg : pos    =     12.3 : 1.0\n",
      "              astounding = True              pos : neg    =     11.7 : 1.0\n",
      "                  avoids = True              pos : neg    =     11.7 : 1.0\n",
      "             fascination = True              pos : neg    =     11.0 : 1.0\n",
      "               affecting = True              pos : neg    =     10.3 : 1.0\n",
      "               animators = True              pos : neg    =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, cool. What about on some new data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wow! That's about all one :  neg  (0.31/0.69)\nAnyway, back to the movie :  neg  (0.38/0.62)\n"
     ]
    }
   ],
   "source": [
    "test_reviews = [\n",
    "\"\"\"Wow! That's about all one can say about this movie. The first time that I saw\n",
    "it I was mesmerized. The movie looked so cool and hey, it actually had a good\n",
    "plot. If you haven't seen this movie yet, get out from your cave and see it\n",
    "right away. I have seen this movie umpteen times and it still shocks and\n",
    "surprises me.\"\"\",\n",
    "\"\"\"Anyway, back to the movie. It is as bad as you've no doubt heard. The scene\n",
    "changes from night to day to night, the spaceship is a hubcap (you can see the\n",
    "string it hangs from catch on fire at one point), I could do a better job\n",
    "acting, etc. \"\"\"]\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for review in test_reviews:\n",
    "    review_features = word_feats(word_tokenize(review.lower()))\n",
    "    label = classifier.classify(review_features)\n",
    "    prob_results = classifier.prob_classify(review_features)\n",
    "    prob_str = \" ({0:.2}/{1:.2})\".format(prob_results.prob(\"pos\"), prob_results.prob(\"neg\"))\n",
    "    print(review[:25], \": \", label, prob_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Decision Tree, Support Vector Machines. Ways of improving the features, tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}